{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata: Dict[str, Dict[str,str]] = dict(\n",
    "    lunar = dict(\n",
    "        catalog = '../data/lunar/training/catalogs/apollo12_catalog_GradeA_final.csv',\n",
    "        train_path = '../data/mars/training/data',\n",
    "        test_path = '../data/mars/test/data',\n",
    "    ),\n",
    "    mars = dict(\n",
    "        catalog = '../data/mars/training/catalogs/Mars_InSight_training_catalog_final.csv',\n",
    "        train_path = '../data/lunar/training/data/S12_GradeA',\n",
    "        test_path = '../data/lunar/test/data'\n",
    "    )\n",
    ")\n",
    "\n",
    "def recursive_search(parent: str) -> Generator[str, None, None]:\n",
    "    for child in os.listdir(parent):\n",
    "        child_path = os.path.join(parent, child)\n",
    "        if os.path.isdir(child_path):\n",
    "            yield from recursive_search(child_path)\n",
    "        elif child.endswith('.csv'):\n",
    "            yield child_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msilib import sequence\n",
    "from lightning.pytorch import LightningDataModule\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Dict, List, Generator, Tuple\n",
    "from torch.utils.data import Dataset\n",
    "from torch import Tensor\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, sequence_length: int) -> None:\n",
    "        self.sequence_length = sequence_length\n",
    "        self.filepaths = [filename for filename in recursive_search('../data/mars/training/data')] + \\\n",
    "                        [filename for filename in recursive_search('../data/lunar/training/data')]\n",
    "        self.meta_lunar: pd.DataFrame = pd.read_csv(metadata['lunar']['catalog'], index_col = ['filename'])\n",
    "        self.meta_mars: pd.DataFrame = pd.read_csv(metadata['mars']['catalog'], index_col = ['filename'])\n",
    "        self.metadata: pd.DataFrame = pd.concat(\n",
    "            [\n",
    "                self.meta_lunar,\n",
    "                self.meta_mars,\n",
    "            ], axis = 0\n",
    "        )\n",
    "\n",
    "    def zero_padding(self, x: torch.Tensor, length: int = 60) -> torch.Tensor:\n",
    "        pad_size = length - x.size(-1)\n",
    "        if pad_size > 0:\n",
    "            return torch.nn.functional.pad(x, (0, pad_size))\n",
    "        return x\n",
    "    \n",
    "    def preprocessing(self) -> None:\n",
    "        self.data: List[Tuple[Tensor, Tensor]] = []\n",
    "        for file in self.filepaths:\n",
    "            try:\n",
    "                arrive = self.metadata.loc[['time_rel(sec)'], file]\n",
    "                out: Tensor = self.get_data(file)\n",
    "                self.data.extend((input, target)) ### mirar\n",
    "            except IndexError:\n",
    "                continue\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def get_data(self, file: str) -> List[Tuple[Tensor, Tensor]]: ## atencion\n",
    "        ## get target (tensor de 0 y 1s tal que el idx del arrival este coincidiendo con el arrival real)\n",
    "        print(self.metadata[\"time_rel(sec)\"].loc[os.path.basename(file)])\n",
    "        ## creas el tensor\n",
    "        \n",
    "        df: pd.DataFrame = pd.read_csv(file, parse_dates =['time_abs(%Y-%m-%dT%H:%M:%S.%f)'] ,index_col = ['time_abs(%Y-%m-%dT%H:%M:%S.%f)'])\n",
    "        velocity: Tensor = torch.from_numpy(df[\"velocity(c/s)\"].resample('s').mean().values)\n",
    "        target = torch.zeros((velocity.shape))\n",
    "        # target = \n",
    "        max: Tensor = torch.from_numpy(df.resample('s').max().values)\n",
    "        min: Tensor = torch.from_numpy(df.resample('s').min().values)\n",
    "        ### add the wavelet / fourier transform is needed\n",
    "\n",
    "        ### separar de a sequence_length\n",
    "        ### input(sequence_length, input_size) -> target(sequence_length) (0, 0, 1, 0)\n",
    "        return tuple(self.zero_padding(i) for i in velocity.split(self.sequence_length)) #target)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[Tensor, Tensor]:\n",
    "        filename: str = self.metadata[idx]\n",
    "        return self.data[filename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2130.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2.3166e+02, 2.2006e+02, 1.7895e+02, 1.9109e+02, 1.7878e+02, 1.6507e+02,\n",
       "        1.4346e+02, 1.1570e+02, 1.2584e+02, 1.2864e+02, 1.2163e+02, 1.3797e+02,\n",
       "        9.3658e+01, 9.8850e+01, 9.0091e+01, 8.4632e+01, 9.9423e+01, 1.3291e+02,\n",
       "        1.6241e+02, 1.6645e+02, 1.8494e+02, 2.0618e+02, 1.7522e+02, 2.0021e+02,\n",
       "        1.8730e+02, 1.7772e+02, 1.7130e+02, 1.5150e+02, 1.6209e+02, 1.5609e+02,\n",
       "        1.6114e+02, 1.8311e+02, 1.8972e+02, 1.7930e+02, 1.6509e+02, 1.6191e+02,\n",
       "        1.3282e+02, 1.3052e+02, 1.2823e+02, 9.9613e+01, 9.2671e+01, 6.3208e+01,\n",
       "        6.9348e+01, 6.3965e+01, 5.3418e+01, 5.2325e+01, 5.2556e+01, 5.0903e+01,\n",
       "        4.5167e+01, 3.7608e+01, 3.5124e+01, 2.9001e+01, 2.1964e+01, 1.5242e+01,\n",
       "        9.7051e+00, 6.1164e+00, 3.2394e+00, 1.7777e+00, 6.4901e-01, 8.0729e-02],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TrainDataset(60)\n",
    "dataset.get_data(dataset.filepaths[0])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
